{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#selenium, web scraper\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from re import sub, match\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium.webdriver.support import ui\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.amazon.com/Best-Books-of-the-Year-So-Far/b/ref=bhp_brws_boty19?ie=UTF8&node=3003015011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-leftnav&pf_rd_r=T4F5B1C20GNF2222R2HA&pf_rd_r=T4F5B1C20GNF2222R2HA&pf_rd_t=101&pf_rd_p=dfe90ba6-2174-4c8c-9c55-9e9b4d012467&pf_rd_p=dfe90ba6-2174-4c8c-9c55-9e9b4d012467&pf_rd_i=283155')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the books link categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_link, category_genre = [], []\n",
    "#The best books of 2020 so far by category\n",
    "best_book = driver.find_elements_by_class_name(\"bxc-grid__container.bxc-grid__container--width-1500\")[-1] # 3 elements\n",
    "#ows of book categories\n",
    "rows_categories = best_book.find_elements_by_class_name(\"bxc-grid__row.bxc-grid__row--light \") # 4 elements\n",
    "#loop for each category row\n",
    "for idx, val in enumerate(rows_categories):\n",
    "    #the first itteration is book's banner, so we need to skip that\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    #every row return 4 elements\n",
    "    category_links = val.find_elements_by_tag_name('a') \n",
    "    #loop for each link\n",
    "    for link in category_links:\n",
    "        #the url from tag a\n",
    "        category_link.append(link.get_property('href'))\n",
    "        #save the book genre to the list\n",
    "        category_genre.append(link.get_attribute('aria-label'))\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the link url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [03:11<00:00, 15.99s/it]\n"
     ]
    }
   ],
   "source": [
    "#list of book link, list of general book genre (value from category_genre), list of book status (best seller)\n",
    "books_link, books_genre, book_status, index = [], [], [], 0\n",
    "\n",
    "#tqdm is used to display the progress precentage when we run the looping process\n",
    "for link in tqdm (category_link):\n",
    "    #go to book link\n",
    "    driver.get(link)\n",
    "    #we need stop our progress in 3 second to wait the website loading the data\n",
    "    sleep(3)\n",
    "    \n",
    "    \"\"\"\n",
    "    flaq : to check last pg_nation page. If it's the last, the flaq value will assign with false\n",
    "    page : to check  is it the first page? because the css structure is different between the first and\n",
    "           the page after we press next pg_nation button. So I need make 2 condition to handle this case.\n",
    "    \"\"\"\n",
    "    flaq, page = True, 0\n",
    "    #get data for each category with its PG-nation\n",
    "    while flaq:\n",
    "        #check the first page\n",
    "        if page == 0: \n",
    "            #container for all books list\n",
    "            all_book_lists = driver.find_element_by_xpath(\"/html/body/div[2]/div[3]/div/div[1]/div/div[2]/div[2]\")\n",
    "            #container for each books\n",
    "            books_data = all_book_lists.find_elements_by_class_name(\"s-result-item.celwidget\") #return list\n",
    "            #Itteration of the book link\n",
    "            for data in books_data:\n",
    "                #title element\n",
    "                book_title = data.find_element_by_class_name(\"a-row.a-spacing-small\")\n",
    "                #get a url from the title\n",
    "                books_link.append(book_title.find_element_by_xpath(\"div[1]/a\").get_property('href'))\n",
    "                \n",
    "                #assign books_genre with category_genre, so we will get the same genre before change the book category\n",
    "                books_genre.append(category_genre[index])\n",
    "                \n",
    "                #book_status (best seller, teacher's pick, etc)\n",
    "                try:\n",
    "                    #book status container\n",
    "                    book_reword = data.find_element_by_class_name(\"a-row.sx-badge-region.sx-pinned-top-badge\")\n",
    "                    #assign the status into array\n",
    "                    book_status.append(book_reword.find_element_by_xpath(\"div/a/span[1]/span/span\").text)\n",
    "                except:\n",
    "                    #we will get a null element if that book doesn't have status container (error handling), assign with \"\"\n",
    "                    book_status.append(\"\")\n",
    "                    continue\n",
    "        # if this is the second page or more       \n",
    "        else:\n",
    "            #container for all books list\n",
    "            all_book_lists_2 = driver.find_element_by_class_name(\"s-main-slot.s-result-list.s-search-results.sg-row\")\n",
    "            #container for each books\n",
    "            books_data =  all_book_lists_2.find_elements_by_class_name(\"sg-col-20-of-24.s-result-item.s-asin.sg-col-0-of-12.sg-col-28-of-32.sg-col-16-of-20.sg-col.sg-col-32-of-36.sg-col-12-of-16.sg-col-24-of-28\")\n",
    "            #Itteration of the book link\n",
    "            for data in books_data:\n",
    "                #title element\n",
    "                book_title = data.find_element_by_class_name(\"a-size-mini.a-spacing-none.a-color-base.s-line-clamp-2\")\n",
    "                #get a url from the title\n",
    "                books_link.append(book_title.find_element_by_xpath(\"a\").get_property('href'))\n",
    "        \n",
    "                #books_genre\n",
    "                books_genre.append(category_genre[index])\n",
    "                \n",
    "                #book_status \n",
    "                try:\n",
    "                    book_reword = data.find_element_by_class_name(\"a-badge-label-inner.a-text-ellipsis\")\n",
    "                    book_status.append(book_reword.find_element_by_xpath(\"span\").text)\n",
    "                except:\n",
    "                    book_status.append(\"\")\n",
    "                    continue\n",
    "        \n",
    "        #next button handling \n",
    "        try:\n",
    "            #handling the first page\n",
    "            page += 1\n",
    "            #take the url from \">\" button\n",
    "            next_button = driver.find_element_by_class_name(\"pagnRA\").find_element_by_tag_name('a').get_property('href')\n",
    "            driver.get(next_button)\n",
    "            sleep(2)\n",
    "        except:\n",
    "            try:\n",
    "                #handling the  second page or more\n",
    "                next_button = driver.find_element_by_class_name(\"a-last\").find_element_by_tag_name('a').get_property('href')\n",
    "                driver.get(next_button)\n",
    "                sleep(2)\n",
    "            except:\n",
    "                #when we don't find the next button (mean the itteration already done and go to the next category)\n",
    "                flaq=False\n",
    "                break\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buku = pd.DataFrame()\n",
    "buku['url'] = books_link\n",
    "buku.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scraper blue print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_number = {'january':'01', 'february':'02', 'march':'03', 'april':'04', 'may':'05', 'june':'06', 'july':'07',\n",
    "               'august':'08', 'september':'09', 'october':'10', 'november':'11', 'december':'12'}\n",
    "date_number = {'1':'01', '2':'02', '3':'03', '4':'04', '5':'05',\n",
    "               '6':'06', '7':'07', '8':'08', '9':'09'}\n",
    "\n",
    "def get_scrape_blueprint(driver, index):\n",
    "    \"\"\"\n",
    "    driver : WebDriver that access the link\n",
    "    index  : use to access the list of books_genre and book_status\n",
    "    \"\"\"\n",
    "    #the specifict genre on that page\n",
    "    genre = driver.find_elements_by_class_name('a-link-normal.a-color-tertiary')[2].text\n",
    "    #the book title\n",
    "    title = driver.find_element_by_id('productTitle').text\n",
    "    \n",
    "    #I used this exception hendling to handle different page structure after clicked the next pg_nation\n",
    "    author, ratting, total_ratting  = \"\", 0, 0 \n",
    "    #author\n",
    "    try:\n",
    "        #author value from the first page\n",
    "        author = driver.find_element_by_class_name(\"a-size-small.a-link-normal.authorNameLink.a-text-normal\").text\n",
    "    except:\n",
    "        try:\n",
    "            #author value on the next page\n",
    "            container_author = driver.find_elements_by_class_name(\"author.notFaded\")[0]\n",
    "            author = container_author.find_element_by_xpath(\"a\").text\n",
    "        except:\n",
    "            print(\"author not found\")\n",
    "    #ratting\n",
    "    try:\n",
    "        #ratting value from the first page, covert the datatype to float \n",
    "        ratting = float(driver.find_element_by_class_name(\"a-size-base.a-nowrap\").find_element_by_class_name(\"a-size-medium.a-color-base\").text.split()[0])\n",
    "    except:\n",
    "        #ratting value on the next page, covert the datatype to float\n",
    "        ratting_container = driver.find_element_by_id(\"detailBullets_averageCustomerReviews\")\n",
    "        ratting = float(ratting_container.find_element_by_xpath(\"span[1]/span\").get_attribute('title').split()[0])\n",
    "    #total ratting\n",
    "    try:\n",
    "        #the number of total review from the first page, covert the datatype to int\n",
    "        total_ratting = int(sub(r'[^\\d.]', '', driver.find_element_by_class_name('a-row.a-spacing-medium.averageStarRatingNumerical').find_element_by_class_name('a-size-base.a-color-secondary').text.split()[0]))\n",
    "    except:\n",
    "        #the number of total review on the next page, covert the datatype to int\n",
    "        ratting_container = driver.find_element_by_id(\"detailBullets_averageCustomerReviews\")\n",
    "        review = ratting_container.find_element_by_id(\"acrCustomerReviewText\").text\n",
    "        total_ratting = int(sub(r'[^\\d.]', '', review).split()[0])\n",
    "    \n",
    "    #Every book has difference price, a book can have one, 2 or five kinds of price and we need to handle it.\n",
    "    kindle_price, audiobook_price, hardcover_price, paperback_price, audioplayer_price, board_book_price = 0,0,0,0,0,0\n",
    "    #element of price list\n",
    "    container_price_list = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "    #price list\n",
    "    get_price_lists = container_price_list.find_elements_by_tag_name('li')\n",
    "    #price list itteration\n",
    "    for price_list in get_price_lists:\n",
    "        try:\n",
    "            #price type\n",
    "            kind_price_method = price_list.find_element_by_xpath('span/span[1]/span/a/span[1]').text\n",
    "            #price value\n",
    "            price_method = float(price_list.find_element_by_xpath('span/span[1]/span/a/span[2]/span').text.split(\"$\")[1])\n",
    "            #save the value in the different variable\n",
    "            if kind_price_method == 'Kindle':\n",
    "                kindle_price = price_method\n",
    "            elif kind_price_method == 'Audiobook':\n",
    "                audiobook_price = price_method\n",
    "            elif kind_price_method == 'Hardcover':\n",
    "                hardcover_price = price_method\n",
    "            elif kind_price_method == 'Paperback':\n",
    "                paperback_price = price_method\n",
    "            elif kind_price_method == 'Preloaded Digital Audio Player':\n",
    "                audioplayer_price = price_method\n",
    "            elif kind_price_method == 'Board book':\n",
    "                board_book_price = price_method\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    #product detail\n",
    "    publication_date, file_size, publisher, word_wise, print_length, language = \"\", 0, \"\", \"\", 0, \"\" \n",
    "    asin, text_to_speach, enhanced_typesetting, x_ray, lending, simultaneous_device_usage, screen_reader = \"\", \"\", \"\", \"\", \"\", \"\", \"\" \n",
    "    #product detail element (ul)\n",
    "    product_detail_ul = driver.find_elements_by_class_name('a-unordered-list.a-nostyle.a-vertical.a-spacing-none.detail-bullet-list')[0]\n",
    "    #product detail list (li)\n",
    "    product_detail_li =product_detail_ul.find_elements_by_tag_name('li')\n",
    "    #product detail itteration\n",
    "    for idx, detail in enumerate(product_detail_li): \n",
    "        #attribute name\n",
    "        word = detail.find_element_by_xpath('span/span[1]').text\n",
    "        if word == 'Word Wise :':\n",
    "            word_wise = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Print length :':\n",
    "            print_length = int(detail.find_element_by_xpath('span/span[2]').text.split()[0]) #convert to int\n",
    "        #not all booke has publisher date, so I took the publish date from this publisher\n",
    "        elif word == 'Publisher :':\n",
    "            #publisher name\n",
    "            publisher = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[0].rstrip()\n",
    "            #publish date\n",
    "            try:\n",
    "                #value like : title title title (November 7, 2020)\n",
    "                publisher_date = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[1].split(\")\")[0].split()\n",
    "                #covert month to number (month_number dictionary)\n",
    "                month = month_number[publisher_date[0].lower()]\n",
    "                #convert day to number format (date_number dictionary)\n",
    "                day = match(\"\\d+\", publisher_date[1]).group(0) \n",
    "                if day in date_number.keys():\n",
    "                    day = date_number[match(\"\\d+\", publisher_date[1]).group(0)]\n",
    "                year = publisher_date[2]\n",
    "                publication_date = year+month+day\n",
    "            except:\n",
    "                try:\n",
    "                    #value like : title title (YBR) title (November 7, 2020)\n",
    "                    publisher_date = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[2].split(\")\")[0].split()\n",
    "                    #covert month to number (month_number dictionary)\n",
    "                    month = month_number[publisher_date[0].lower()]\n",
    "                    #convert day to number format (date_number dictionary)\n",
    "                    day = match(\"\\d+\", publisher_date[1]).group(0) \n",
    "                    if day in date_number.keys():\n",
    "                        day = date_number[match(\"\\d+\", publisher_date[1]).group(0)]\n",
    "                    year = publisher_date[2]\n",
    "                    publication_date = year+month+day\n",
    "                except:\n",
    "                    continue                 \n",
    "        elif word == 'File size :':\n",
    "            file_size = int(detail.find_element_by_xpath('span/span[2]').text.split()[0]) #only take the number\n",
    "        elif word == 'Language: :':\n",
    "            language = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'ASIN :':\n",
    "            asin = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Enhanced typesetting :':\n",
    "            enhanced_typesetting = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'X-Ray :':\n",
    "            x_ray = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Screen Reader :':\n",
    "            screen_reader = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Simultaneous device usage :':\n",
    "            simultaneous_device_usage = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Text-to-Speech :':\n",
    "            text_to_speach = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Lending :':\n",
    "            lending = detail.find_element_by_xpath('span/span[2]').text\n",
    "    \n",
    "    #get the book containt \n",
    "    book_content = \"\"\n",
    "    try:\n",
    "        #click read_more button\n",
    "        driver.find_elements_by_id(\"bdSeeAllPrompt\")[0].click()\n",
    "        sleep(3)\n",
    "        #switch to Iframe mode\n",
    "        driver.switch_to.frame(driver.find_element_by_xpath(\"//iframe[@id='bookDesc_iframe']\"))\n",
    "        #get the book containt\n",
    "        book_content = driver.find_element_by_id(\"iframeContent\").text\n",
    "    except:\n",
    "        try: #there isn't read more button\n",
    "            #switch to Iframe mode\n",
    "            driver.switch_to.frame(driver.find_element_by_xpath(\"//iframe[@id='bookDesc_iframe']\"))\n",
    "            #get the book containt\n",
    "            book_content = driver.find_element_by_id(\"iframeContent\").text\n",
    "        except:\n",
    "            print(\"error book review !\")\n",
    "            \n",
    "    \n",
    "    #save data into dictionary\n",
    "    book_scraper = {\n",
    "        'general_genre': books_genre[index],\n",
    "        'book_status': book_status[index],\n",
    "        'genre': genre,\n",
    "        'title': title,\n",
    "        'author': author,\n",
    "        'ratting': ratting,\n",
    "        'total_ratting': total_ratting,\n",
    "        'kindle_price' : kindle_price,\n",
    "        'audiobook_price' : audiobook_price,\n",
    "        'hardcover_price' : hardcover_price,\n",
    "        'paperback_price' : paperback_price,\n",
    "        'audioplayer_price' : audioplayer_price,\n",
    "        'board_book_price' : board_book_price,\n",
    "        'publication_date' : publication_date,\n",
    "        'file_size': file_size,\n",
    "        'publisher': publisher,\n",
    "        'word_wise': word_wise,\n",
    "        'print_length': print_length,\n",
    "        'language': language,\n",
    "        'asin': asin,\n",
    "        'text_to_speach': text_to_speach,\n",
    "        'enhanced_typesetting': enhanced_typesetting,\n",
    "        'x_ray': x_ray,\n",
    "        'lending': lending,\n",
    "        'simultaneous_device_usage': simultaneous_device_usage,\n",
    "        'screen_reader': screen_reader,\n",
    "        'book_content' : book_content,\n",
    "        'book_link':link\n",
    "    }\n",
    "    \n",
    "    return book_scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▍                                                        | 82/272 [17:45<40:42, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to crawlling book's data in index- 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 272/272 [57:37<00:00, 12.71s/it]\n"
     ]
    }
   ],
   "source": [
    "#save scraper data into book_scrape_result, index to access the list of books_genre and book_status\n",
    "book_scrape_result, link_number = [], -1\n",
    "\n",
    "for link in tqdm(books_link):\n",
    "    #go to the book details page\n",
    "    driver.get(link)\n",
    "    sleep(2)\n",
    "    link_number += 1\n",
    "    \n",
    "    #We scrape the data from \"Kindle menu\" because most of books has this price type, so we need to check first. \n",
    "    # whether the kindle price is selected or not\n",
    "    item_selected = \"\"\n",
    "    try: #first page\n",
    "        #container element of selected price type\n",
    "        price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        #element of selected price type\n",
    "        selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected\")\n",
    "        #price type\n",
    "        item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "    except:\n",
    "        try: #next page\n",
    "            price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "            selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected.resizedSwatchElement\")\n",
    "            item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "        except:\n",
    "            print(\"Fail to find kindle button in book-\",link_number)\n",
    "            \n",
    "    \n",
    "    if item_selected == 'Kindle':\n",
    "        try:\n",
    "            sleep(2)\n",
    "            #call get_scrape_blueprint function\n",
    "            book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "            #save the risult into array of book_scraper_result\n",
    "            book_scrape_result.append(book_scraper)\n",
    "        except:\n",
    "            print(\"Fail to crawlling the data in book-\",link_number)\n",
    "    else:\n",
    "        try:\n",
    "            #we need to go to kindle page if the selected price type is not kindle\n",
    "            kindle_button = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "            #get the kindle url\n",
    "            kindle_link = kindle_button.find_element_by_xpath('li[1]/span/span[1]/span/a').get_property('href')\n",
    "            #go to kindle page\n",
    "            driver.get(kindle_link)\n",
    "            sleep(3)\n",
    "            \n",
    "            #call get_scrape_blueprint function\n",
    "            book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "            #save the risult into array of book_scraper_result\n",
    "            book_scrape_result.append(book_scraper)\n",
    "        except:\n",
    "            try:\n",
    "                #if we just have single list, but it is not kindle. We try to scrape that data if it could\n",
    "                book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "                book_scrape_result.append(book_scraper)\n",
    "            except:\n",
    "                print(\"Fail to crawlling book's data in index-\",link_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into dataframe\n",
    "book_scrape_result = pd.DataFrame(book_scrape_result)\n",
    "#save the data into csv\n",
    "book_scrape_result.to_csv(\"amazone_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>general_genre</th>\n",
       "      <th>book_status</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>ratting</th>\n",
       "      <th>total_ratting</th>\n",
       "      <th>kindle_price</th>\n",
       "      <th>audiobook_price</th>\n",
       "      <th>hardcover_price</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>asin</th>\n",
       "      <th>text_to_speach</th>\n",
       "      <th>enhanced_typesetting</th>\n",
       "      <th>x_ray</th>\n",
       "      <th>lending</th>\n",
       "      <th>simultaneous_device_usage</th>\n",
       "      <th>screen_reader</th>\n",
       "      <th>book_content</th>\n",
       "      <th>book_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td></td>\n",
       "      <td>Specific Groups</td>\n",
       "      <td>Untamed</td>\n",
       "      <td>Glennon Doyle</td>\n",
       "      <td>4.7</td>\n",
       "      <td>21797</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>B07VSZTKJ8</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>#1 NEW YORK TIMES BESTSELLER • “Packed with in...</td>\n",
       "      <td>https://www.amazon.com/Untamed-Glennon-Doyle-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td>Best Seller</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>The Splendid and the Vile: A Saga of Churchill...</td>\n",
       "      <td>Erik Larson</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9081</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.24</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>B07TRVW6VX</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>#1 NEW YORK TIMES BESTSELLER • The author of T...</td>\n",
       "      <td>https://www.amazon.com/Splendid-Vile-Churchill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td>Best Seller</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>Hidden Valley Road: Inside the Mind of an Amer...</td>\n",
       "      <td>Robert Kolker</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3868</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.19</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>B07TZYFR71</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>OPRAH’S BOOK CLUB PICK\\n#1 NEW YORK TIMES BEST...</td>\n",
       "      <td>https://www.amazon.com/Hidden-Valley-Road-Insi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td>Best Seller</td>\n",
       "      <td>Arts &amp; Photography</td>\n",
       "      <td>More Myself: A Journey</td>\n",
       "      <td>Alicia Keys</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1882</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.98</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>B07NP3FDVD</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>An intimate, revealing look at one artist’s jo...</td>\n",
       "      <td>https://www.amazon.com/More-Myself-Journey-Ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td></td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>Wow, No Thank You.: Essays</td>\n",
       "      <td>Samantha Irby</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1211</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>B07W3J49XM</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>*AN INSTANT #1 NEW YORK TIMES BESTSELLER*\\n\\n“...</td>\n",
       "      <td>https://www.amazon.com/Wow-No-Thank-You-Essays...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             general_genre  book_status                  genre  \\\n",
       "0  Biographies and memoirs                     Specific Groups   \n",
       "1  Biographies and memoirs  Best Seller  Biographies & Memoirs   \n",
       "2  Biographies and memoirs  Best Seller  Biographies & Memoirs   \n",
       "3  Biographies and memoirs  Best Seller     Arts & Photography   \n",
       "4  Biographies and memoirs               Humor & Entertainment   \n",
       "\n",
       "                                               title         author  ratting  \\\n",
       "0                                            Untamed  Glennon Doyle      4.7   \n",
       "1  The Splendid and the Vile: A Saga of Churchill...    Erik Larson      4.7   \n",
       "2  Hidden Valley Road: Inside the Mind of an Amer...  Robert Kolker      4.6   \n",
       "3                             More Myself: A Journey    Alicia Keys      4.8   \n",
       "4                         Wow, No Thank You.: Essays  Samantha Irby      4.3   \n",
       "\n",
       "   total_ratting  kindle_price  audiobook_price  hardcover_price  ...  \\\n",
       "0          21797         13.30              0.0            16.50  ...   \n",
       "1           9081         14.99              0.0            18.24  ...   \n",
       "2           3868         14.99              0.0            16.19  ...   \n",
       "3           1882          2.99              0.0            20.98  ...   \n",
       "4           1211          9.99              0.0             0.00  ...   \n",
       "\n",
       "   language        asin  text_to_speach enhanced_typesetting    x_ray  \\\n",
       "0   English  B07VSZTKJ8         Enabled              Enabled  Enabled   \n",
       "1   English  B07TRVW6VX         Enabled              Enabled  Enabled   \n",
       "2   English  B07TZYFR71         Enabled              Enabled  Enabled   \n",
       "3   English  B07NP3FDVD         Enabled              Enabled  Enabled   \n",
       "4   English  B07W3J49XM         Enabled              Enabled  Enabled   \n",
       "\n",
       "       lending simultaneous_device_usage  screen_reader  \\\n",
       "0  Not Enabled                                            \n",
       "1  Not Enabled                                            \n",
       "2  Not Enabled                                            \n",
       "3  Not Enabled                                            \n",
       "4  Not Enabled                                            \n",
       "\n",
       "                                        book_content  \\\n",
       "0  #1 NEW YORK TIMES BESTSELLER • “Packed with in...   \n",
       "1  #1 NEW YORK TIMES BESTSELLER • The author of T...   \n",
       "2  OPRAH’S BOOK CLUB PICK\\n#1 NEW YORK TIMES BEST...   \n",
       "3  An intimate, revealing look at one artist’s jo...   \n",
       "4  *AN INSTANT #1 NEW YORK TIMES BESTSELLER*\\n\\n“...   \n",
       "\n",
       "                                           book_link  \n",
       "0  https://www.amazon.com/Untamed-Glennon-Doyle-e...  \n",
       "1  https://www.amazon.com/Splendid-Vile-Churchill...  \n",
       "2  https://www.amazon.com/Hidden-Valley-Road-Insi...  \n",
       "3  https://www.amazon.com/More-Myself-Journey-Ali...  \n",
       "4  https://www.amazon.com/Wow-No-Thank-You-Essays...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_scrape_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'general_genre': 'Biographies and memoirs',\n",
       "  'book_status': 'Best Seller',\n",
       "  'genre': 'Engineering',\n",
       "  'title': 'How Innovation Works: And Why It Flourishes in Freedom',\n",
       "  'author': 'Matt Ridley',\n",
       "  'ratting': 4.6,\n",
       "  'total_ratting': 436,\n",
       "  'kindle_price': 15.99,\n",
       "  'audiobook_price': 0.0,\n",
       "  'hardcover_price': 20.49,\n",
       "  'paperback_price': 17.99,\n",
       "  'audioplayer_price': 0,\n",
       "  'board_book_price': 0,\n",
       "  'publication_date': '20200519',\n",
       "  'file_size': 1395,\n",
       "  'publisher': 'Harper',\n",
       "  'word_wise': 'Enabled',\n",
       "  'print_length': 416,\n",
       "  'language': 'English',\n",
       "  'asin': 'B07WSBV7YZ',\n",
       "  'text_to_speach': 'Enabled',\n",
       "  'enhanced_typesetting': 'Enabled',\n",
       "  'x_ray': 'Enabled',\n",
       "  'lending': 'Not Enabled',\n",
       "  'simultaneous_device_usage': '',\n",
       "  'screen_reader': '',\n",
       "  'book_content': 'Building on his national bestseller The Rational Optimist, Matt Ridley chronicles the history of innovation, and how we need to change our thinking on the subject.\\n\\nInnovation is the main event of the modern age, the reason we experience both dramatic improvements in our living standards and unsettling changes in our society. Forget short-term symptoms like Donald Trump and Brexit, it is innovation that will shape the twenty-first century. Yet innovation remains a mysterious process, poorly understood by policy makers and businessmen alike.\\nMatt Ridley argues that we need to see innovation as an incremental, bottom-up, fortuitous process that happens as a direct result of the human habit of exchange, rather than an orderly, top-down process developing according to a plan. Innovation is crucially different from invention, because it is the turning of inventions into things of practical and affordable use to people. It speeds up in some sectors and slows down in others. It is always a collective, collaborative phenomenon, involving trial and error, not a matter of lonely genius. It happens mainly in just a few parts of the world at any one time. It still cannot be modeled properly by economists, but it can easily be discouraged by politicians. Far from there being too much innovation, we may be on the brink of an innovation famine.\\nRidley derives these and other lessons from the lively stories of scores of innovations, how they started and why they succeeded or failed. Some of the innovation stories he tells are about steam engines, jet engines, search engines, airships, coffee, potatoes, vaping, vaccines, cuisine, antibiotics, mosquito nets, turbines, propellers, fertilizer, zero, computers, dogs, farming, fire, genetic engineering, gene editing, container shipping, railways, cars, safety rules, wheeled suitcases, mobile phones, corrugated iron, powered flight, chlorinated water, toilets, vacuum cleaners, shale gas, the telegraph, radio, social media, block chain, the sharing economy, artificial intelligence, fake bomb detectors, phantom games consoles, fraudulent blood tests, hyperloop tubes, herbicides, copyright, and even life itself.',\n",
       "  'book_link': 'https://www.amazon.com/More-than-Ready-Strong-Lessons/dp/1580059481/ref=sr_1_20?dchild=1&qid=1605122975&s=books&sr=1-20'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Treck the error by access the book url (without looping) --> driver.get(buku.iloc[book index][0])\n",
    "But you can also add looping to get some data from book lists with message \"error book review\". \n",
    "This case happen when your connection is not stabil, so you just need to re-open the link --> get data --> merge with the previous data\n",
    "\"\"\"\n",
    "driver.get(buku.iloc[19][0])\n",
    "sleep(3)\n",
    "link_number = 1\n",
    "xx = []\n",
    "\n",
    "#checking price selected\n",
    "item_selected = \"\"\n",
    "try:\n",
    "    price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "    selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected\")\n",
    "    item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "except:\n",
    "    try:\n",
    "        price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected.resizedSwatchElement\")\n",
    "        item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "    except:\n",
    "        print(\"Fail to find kindle button in book-\",link_number)\n",
    "\n",
    "\n",
    "if item_selected == 'Kindle':\n",
    "    try:\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "    except:\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "else:\n",
    "    try:\n",
    "        #go to kindle page\n",
    "        kindle_button = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        kindle_link = kindle_button.find_element_by_xpath('li[1]/span/span[1]/span/a').get_property('href')\n",
    "        driver.get(kindle_link)\n",
    "        sleep(3)\n",
    "\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "    except:\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCROLL DOWN (u can use this instruction in every website to scroll down its page)\n",
    "\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
