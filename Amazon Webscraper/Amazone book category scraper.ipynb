{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#selenium, web scraper\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "from re import sub, match\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.amazon.com/Best-Books-of-the-Year-So-Far/b/ref=bhp_brws_boty19?ie=UTF8&node=3003015011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-leftnav&pf_rd_r=T4F5B1C20GNF2222R2HA&pf_rd_r=T4F5B1C20GNF2222R2HA&pf_rd_t=101&pf_rd_p=dfe90ba6-2174-4c8c-9c55-9e9b4d012467&pf_rd_p=dfe90ba6-2174-4c8c-9c55-9e9b4d012467&pf_rd_i=283155')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the books link categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_link, category_genre = [], []\n",
    "#The best books of 2020 so far by category\n",
    "best_book = driver.find_elements_by_class_name(\"bxc-grid__container.bxc-grid__container--width-1500\")[-1] # 3 elements\n",
    "#ows of book categories\n",
    "rows_categories = best_book.find_elements_by_class_name(\"bxc-grid__row.bxc-grid__row--light \") # 4 elements\n",
    "#loop for each category row\n",
    "for idx, val in enumerate(rows_categories):\n",
    "    #the first itteration is book's banner, so we need to skip that\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    #every row return 4 elements\n",
    "    category_links = val.find_elements_by_tag_name('a') \n",
    "    #loop for each link\n",
    "    for link in category_links:\n",
    "        #the url from tag a\n",
    "        category_link.append(link.get_property('href'))\n",
    "        #save the book genre to the list\n",
    "        category_genre.append(link.get_attribute('aria-label'))\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the link url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [02:43<00:00, 13.59s/it]\n"
     ]
    }
   ],
   "source": [
    "#list of book link, list of general book genre (value from category_genre), list of book status (best seller)\n",
    "books_link, books_genre, book_status, index = [], [], [], 0\n",
    "\n",
    "#tqdm is used to display the progress precentage when we run the looping process\n",
    "for link in tqdm (category_link):\n",
    "    #go to book link\n",
    "    driver.get(link)\n",
    "    #we need stop our progress in 3 second to wait the website loading the data\n",
    "    sleep(3)\n",
    "    \n",
    "    \"\"\"\n",
    "    flaq : to check last pg_nation page. If it's the last, the flaq value will assign with false\n",
    "    page : to check  is it the first page? because the css structure is different between the first and\n",
    "           the page after we press next pg_nation button. So I need make 2 condition to handle this case.\n",
    "    \"\"\"\n",
    "    flaq, page = True, 0\n",
    "    #get data for each category with its PG-nation\n",
    "    while flaq:\n",
    "        #check the first page\n",
    "        if page == 0: \n",
    "            #container for all books list\n",
    "            all_book_lists = driver.find_element_by_xpath(\"/html/body/div[2]/div[3]/div/div[1]/div/div[2]/div[2]\")\n",
    "            #container for each books\n",
    "            books_data = all_book_lists.find_elements_by_class_name(\"s-result-item.celwidget\") #return list\n",
    "            #Itteration of the book link\n",
    "            for data in books_data:\n",
    "                #title element\n",
    "                book_title = data.find_element_by_class_name(\"a-row.a-spacing-small\")\n",
    "                #get a url from the title\n",
    "                books_link.append(book_title.find_element_by_xpath(\"div[1]/a\").get_property('href'))\n",
    "                \n",
    "                #assign books_genre with category_genre, so we will get the same genre before change the book category\n",
    "                books_genre.append(category_genre[index])\n",
    "                \n",
    "                #book_status (best seller, teacher's pick, etc)\n",
    "                try:\n",
    "                    #book status container\n",
    "                    book_reword = data.find_element_by_class_name(\"a-row.sx-badge-region.sx-pinned-top-badge\")\n",
    "                    #assign the status into array\n",
    "                    book_status.append(book_reword.find_element_by_xpath(\"div/a/span[1]/span/span\").text)\n",
    "                except:\n",
    "                    #we will get a null element if that book doesn't have status container (error handling), assign with \"\"\n",
    "                    book_status.append(\"\")\n",
    "                    continue\n",
    "        # if this is the second page or more       \n",
    "        else:\n",
    "            #container for all books list\n",
    "            all_book_lists_2 = driver.find_element_by_class_name(\"s-main-slot.s-result-list.s-search-results.sg-row\")\n",
    "            #container for each books\n",
    "            books_data =  all_book_lists_2.find_elements_by_class_name(\"sg-col-20-of-24.s-result-item.s-asin.sg-col-0-of-12.sg-col-28-of-32.sg-col-16-of-20.sg-col.sg-col-32-of-36.sg-col-12-of-16.sg-col-24-of-28\")\n",
    "            #Itteration of the book link\n",
    "            for data in books_data:\n",
    "                #title element\n",
    "                book_title = data.find_element_by_class_name(\"a-size-mini.a-spacing-none.a-color-base.s-line-clamp-2\")\n",
    "                #get a url from the title\n",
    "                books_link.append(book_title.find_element_by_xpath(\"a\").get_property('href'))\n",
    "        \n",
    "                #books_genre\n",
    "                books_genre.append(category_genre[index])\n",
    "                \n",
    "                #book_status \n",
    "                try:\n",
    "                    book_reword = data.find_element_by_class_name(\"a-badge-label-inner.a-text-ellipsis\")\n",
    "                    book_status.append(book_reword.find_element_by_xpath(\"span\").text)\n",
    "                except:\n",
    "                    book_status.append(\"\")\n",
    "                    continue\n",
    "        \n",
    "        #next button handling \n",
    "        try:\n",
    "            #handling the first page\n",
    "            page += 1\n",
    "            #take the url from \">\" button\n",
    "            next_button = driver.find_element_by_class_name(\"pagnRA\").find_element_by_tag_name('a').get_property('href')\n",
    "            driver.get(next_button)\n",
    "            sleep(2)\n",
    "        except:\n",
    "            try:\n",
    "                #handling the  second page or more\n",
    "                next_button = driver.find_element_by_class_name(\"a-last\").find_element_by_tag_name('a').get_property('href')\n",
    "                driver.get(next_button)\n",
    "                sleep(2)\n",
    "            except:\n",
    "                #when we don't find the next button (mean the itteration already done and go to the next category)\n",
    "                flaq=False\n",
    "                break\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buku = pd.DataFrame()\n",
    "buku['url'] = books_link\n",
    "buku.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_number = {'january':'01', 'february':'02', 'march':'03', 'april':'04', 'may':'05', 'june':'06', 'july':'07',\n",
    "               'august':'08', 'september':'09', 'october':'10', 'november':'11', 'december':'12'}\n",
    "date_number = {'1':'01', '2':'02', '3':'03', '4':'04', '5':'05',\n",
    "               '6':'06', '7':'07', '8':'08', '9':'09'}\n",
    "\n",
    "def get_scrape_blueprint(driver, index):\n",
    "    \"\"\"\n",
    "    driver : WebDriver that access the link\n",
    "    index  : use to access the list of books_genre and book_status\n",
    "    \"\"\"\n",
    "    #the specifict genre on that page\n",
    "    genre = driver.find_elements_by_class_name('a-link-normal.a-color-tertiary')[2].text\n",
    "    #the book title\n",
    "    title = driver.find_element_by_id('productTitle').text\n",
    "    \n",
    "    #I used this exception hendling to handle different page structure after clicked the next pg_nation\n",
    "    author, ratting, total_ratting  = \"\", 0, 0 \n",
    "    #author\n",
    "    try:\n",
    "        #author value from the first page\n",
    "        author = driver.find_element_by_class_name(\"a-size-small.a-link-normal.authorNameLink.a-text-normal\").text\n",
    "    except:\n",
    "        try:\n",
    "            #author value on the next page\n",
    "            container_author = driver.find_elements_by_class_name(\"author.notFaded\")[0]\n",
    "            author = container_author.find_element_by_xpath(\"a\").text\n",
    "        except:\n",
    "            print(\"author not found\")\n",
    "    #ratting\n",
    "    try:\n",
    "        #ratting value from the first page, covert the datatype to float \n",
    "        ratting = float(driver.find_element_by_class_name(\"a-size-base.a-nowrap\").find_element_by_class_name(\"a-size-medium.a-color-base\").text.split()[0])\n",
    "    except:\n",
    "        #ratting value on the next page, covert the datatype to float\n",
    "        ratting_container = driver.find_element_by_id(\"detailBullets_averageCustomerReviews\")\n",
    "        ratting = float(ratting_container.find_element_by_xpath(\"span[1]/span\").get_attribute('title').split()[0])\n",
    "    #total ratting\n",
    "    try:\n",
    "        #the number of total review from the first page, covert the datatype to int\n",
    "        total_ratting = int(sub(r'[^\\d.]', '', driver.find_element_by_class_name('a-row.a-spacing-medium.averageStarRatingNumerical').find_element_by_class_name('a-size-base.a-color-secondary').text.split()[0]))\n",
    "    except:\n",
    "        #the number of total review on the next page, covert the datatype to int\n",
    "        ratting_container = driver.find_element_by_id(\"detailBullets_averageCustomerReviews\")\n",
    "        review = ratting_container.find_element_by_id(\"acrCustomerReviewText\").text\n",
    "        total_ratting = int(sub(r'[^\\d.]', '', review).split()[0])\n",
    "    \n",
    "    #Every book has difference price, a book can have one, 2 or five kinds of price and we need to handle it.\n",
    "    kindle_price, audiobook_price, hardcover_price, paperback_price, audioplayer_price, board_book_price = 0,0,0,0,0,0\n",
    "    #element of price list\n",
    "    container_price_list = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "    #price list\n",
    "    get_price_lists = container_price_list.find_elements_by_tag_name('li')\n",
    "    #price list itteration\n",
    "    for price_list in get_price_lists:\n",
    "        try:\n",
    "            #price type\n",
    "            kind_price_method = price_list.find_element_by_xpath('span/span[1]/span/a/span[1]').text\n",
    "            #price value\n",
    "            price_method = float(price_list.find_element_by_xpath('span/span[1]/span/a/span[2]/span').text.split(\"$\")[1])\n",
    "            #save the value in the different variable\n",
    "            if kind_price_method == 'Kindle':\n",
    "                kindle_price = price_method\n",
    "            elif kind_price_method == 'Audiobook':\n",
    "                audiobook_price = price_method\n",
    "            elif kind_price_method == 'Hardcover':\n",
    "                hardcover_price = price_method\n",
    "            elif kind_price_method == 'Paperback':\n",
    "                paperback_price = price_method\n",
    "            elif kind_price_method == 'Preloaded Digital Audio Player':\n",
    "                audioplayer_price = price_method\n",
    "            elif kind_price_method == 'Board book':\n",
    "                board_book_price = price_method\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    #product detail\n",
    "    publication_date, file_size, publisher, word_wise, print_length, language = \"\", 0, \"\", \"\", 0, \"\" \n",
    "    asin, text_to_speach, enhanced_typesetting, x_ray, lending, simultaneous_device_usage, screen_reader = \"\", \"\", \"\", \"\", \"\", \"\", \"\" \n",
    "    #product detail element (ul)\n",
    "    product_detail_ul = driver.find_elements_by_class_name('a-unordered-list.a-nostyle.a-vertical.a-spacing-none.detail-bullet-list')[0]\n",
    "    #product detail list (li)\n",
    "    product_detail_li =product_detail_ul.find_elements_by_tag_name('li')\n",
    "    #product detail itteration\n",
    "    for idx, detail in enumerate(product_detail_li): \n",
    "        #attribute name\n",
    "        word = detail.find_element_by_xpath('span/span[1]').text\n",
    "        if word == 'Word Wise :':\n",
    "            word_wise = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Print length :':\n",
    "            print_length = int(detail.find_element_by_xpath('span/span[2]').text.split()[0]) #convert to int\n",
    "        #not all booke has publisher date, so I took the publish date from this publisher\n",
    "        elif word == 'Publisher :':\n",
    "            #publisher name\n",
    "            publisher = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[0].rstrip()\n",
    "            #publish date\n",
    "            try:\n",
    "                #value like : title title title (November 7, 2020)\n",
    "                publisher_date = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[1].split(\")\")[0].split()\n",
    "                #covert month to number (month_number dictionary)\n",
    "                month = month_number[publisher_date[0].lower()]\n",
    "                #convert day to number format (date_number dictionary)\n",
    "                day = match(\"\\d+\", publisher_date[1]).group(0) \n",
    "                if day in date_number.keys():\n",
    "                    day = date_number[match(\"\\d+\", publisher_date[1]).group(0)]\n",
    "                year = publisher_date[2]\n",
    "                publication_date = year+month+day\n",
    "            except:\n",
    "                try:\n",
    "                    #value like : title title (YBR) title (November 7, 2020)\n",
    "                    publisher_date = detail.find_element_by_xpath('span/span[2]').text.split(\"(\")[2].split(\")\")[0].split()\n",
    "                    #covert month to number (month_number dictionary)\n",
    "                    month = month_number[publisher_date[0].lower()]\n",
    "                    #convert day to number format (date_number dictionary)\n",
    "                    day = match(\"\\d+\", publisher_date[1]).group(0) \n",
    "                    if day in date_number.keys():\n",
    "                        day = date_number[match(\"\\d+\", publisher_date[1]).group(0)]\n",
    "                    year = publisher_date[2]\n",
    "                    publication_date = year+month+day\n",
    "                except:\n",
    "                    continue                 \n",
    "        elif word == 'File size :':\n",
    "            file_size = int(detail.find_element_by_xpath('span/span[2]').text.split()[0]) #only take the number\n",
    "        elif word == 'Language: :':\n",
    "            language = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'ASIN :':\n",
    "            asin = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Enhanced typesetting :':\n",
    "            enhanced_typesetting = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'X-Ray :':\n",
    "            x_ray = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Screen Reader :':\n",
    "            screen_reader = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Simultaneous device usage :':\n",
    "            simultaneous_device_usage = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Text-to-Speech :':\n",
    "            text_to_speach = detail.find_element_by_xpath('span/span[2]').text\n",
    "        elif word == 'Lending :':\n",
    "            lending = detail.find_element_by_xpath('span/span[2]').text\n",
    "    \n",
    "    #save data into dictionary\n",
    "    book_scraper = {\n",
    "        'general_genre': books_genre[index],\n",
    "        'book_status': book_status[index],\n",
    "        'genre': genre,\n",
    "        'title': title,\n",
    "        'author': author,\n",
    "        'ratting': ratting,\n",
    "        'total_ratting': total_ratting,\n",
    "        'kindle_price' : kindle_price,\n",
    "        'audiobook_price' : audiobook_price,\n",
    "        'hardcover_price' : hardcover_price,\n",
    "        'paperback_price' : paperback_price,\n",
    "        'audioplayer_price' : audioplayer_price,\n",
    "        'board_book_price' : board_book_price,\n",
    "        'publication_date': publication_date,\n",
    "        'file_size': file_size,\n",
    "        'publisher': publisher,\n",
    "        'word_wise': word_wise,\n",
    "        'print_length': print_length,\n",
    "        'language': language,\n",
    "        'asin': asin,\n",
    "        'text_to_speach': text_to_speach,\n",
    "        'enhanced_typesetting': enhanced_typesetting,\n",
    "        'x_ray': x_ray,\n",
    "        'lending': lending,\n",
    "        'simultaneous_device_usage': simultaneous_device_usage,\n",
    "        'screen_reader': screen_reader,\n",
    "        'book_link':link\n",
    "    }\n",
    "    \n",
    "    return book_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▍                                                        | 82/272 [15:55<32:40, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to crawlling book's data in index- 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 272/272 [50:27<00:00, 11.13s/it]\n"
     ]
    }
   ],
   "source": [
    "#save scraper data into book_scrape_result, index to access the list of books_genre and book_status\n",
    "book_scrape_result, link_number = [], -1\n",
    "\n",
    "for link in tqdm(books_link):\n",
    "    #go to the book details page\n",
    "    driver.get(link)\n",
    "    sleep(2)\n",
    "    link_number += 1\n",
    "    \n",
    "    #We scrape the data from \"Kindle menu\" because most of books has this price type, so we need to check first. \n",
    "    # whether the kindle price is selected or not\n",
    "    item_selected = \"\"\n",
    "    try: #first page\n",
    "        #container element of selected price type\n",
    "        price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        #element of selected price type\n",
    "        selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected\")\n",
    "        #price type\n",
    "        item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "    except:\n",
    "        try: #next page\n",
    "            price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "            selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected.resizedSwatchElement\")\n",
    "            item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "        except:\n",
    "            print(\"Fail to find kindle button in book-\",link_number)\n",
    "            \n",
    "    \n",
    "    if item_selected == 'Kindle':\n",
    "        try:\n",
    "            #call get_scrape_blueprint function\n",
    "            book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "            #save the risult into array of book_scraper_result\n",
    "            book_scrape_result.append(book_scraper)\n",
    "        except:\n",
    "            print(\"Fail to crawlling the data in book-\",link_number)\n",
    "    else:\n",
    "        try:\n",
    "            #we need to go to kindle page if the selected price type is not kindle\n",
    "            kindle_button = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "            #get the kindle url\n",
    "            kindle_link = kindle_button.find_element_by_xpath('li[1]/span/span[1]/span/a').get_property('href')\n",
    "            #go to kindle page\n",
    "            driver.get(kindle_link)\n",
    "            sleep(3)\n",
    "            \n",
    "            #call get_scrape_blueprint function\n",
    "            book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "            #save the risult into array of book_scraper_result\n",
    "            book_scrape_result.append(book_scraper)\n",
    "        except:\n",
    "            try:\n",
    "                #if we just have single list, but it is not kindle. We try to scrape that data if it could\n",
    "                book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "                book_scrape_result.append(book_scraper)\n",
    "            except:\n",
    "                print(\"Fail to crawlling book's data in index-\",link_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into dataframe\n",
    "book_scrape_result = pd.DataFrame(book_scrape_result)\n",
    "#save the data into csv\n",
    "book_scrape_result.to_csv(\"amazone_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>general_genre</th>\n",
       "      <th>book_status</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>ratting</th>\n",
       "      <th>total_ratting</th>\n",
       "      <th>kindle_price</th>\n",
       "      <th>audiobook_price</th>\n",
       "      <th>hardcover_price</th>\n",
       "      <th>...</th>\n",
       "      <th>print_length</th>\n",
       "      <th>language</th>\n",
       "      <th>asin</th>\n",
       "      <th>text_to_speach</th>\n",
       "      <th>enhanced_typesetting</th>\n",
       "      <th>x_ray</th>\n",
       "      <th>lending</th>\n",
       "      <th>simultaneous_device_usage</th>\n",
       "      <th>screen_reader</th>\n",
       "      <th>book_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td></td>\n",
       "      <td>Specific Groups</td>\n",
       "      <td>Untamed</td>\n",
       "      <td>Glennon Doyle</td>\n",
       "      <td>4.7</td>\n",
       "      <td>20658</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.72</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>English</td>\n",
       "      <td>B07VSZTKJ8</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Untamed-Glennon-Doyle-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td>Best Seller</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>The Splendid and the Vile: A Saga of Churchill...</td>\n",
       "      <td>Erik Larson</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8773</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.24</td>\n",
       "      <td>...</td>\n",
       "      <td>546</td>\n",
       "      <td>English</td>\n",
       "      <td>B07TRVW6VX</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Splendid-Vile-Churchill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td>Best Seller</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>Hidden Valley Road: Inside the Mind of an Amer...</td>\n",
       "      <td>Robert Kolker</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3751</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>...</td>\n",
       "      <td>370</td>\n",
       "      <td>English</td>\n",
       "      <td>B07TZYFR71</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Hidden-Valley-Road-Insi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td></td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>Wow, No Thank You.: Essays</td>\n",
       "      <td>Samantha Irby</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1168</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>311</td>\n",
       "      <td>English</td>\n",
       "      <td>B07W3J49XM</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Wow-No-Thank-You-Essays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biographies and memoirs</td>\n",
       "      <td></td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>Nobody Will Tell You This But Me: A true (as t...</td>\n",
       "      <td>Bess Kalb</td>\n",
       "      <td>4.4</td>\n",
       "      <td>440</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.81</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>English</td>\n",
       "      <td>B07TRX3TXP</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Not Enabled</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Nobody-Will-Tell-You-Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             general_genre  book_status                  genre  \\\n",
       "0  Biographies and memoirs                     Specific Groups   \n",
       "1  Biographies and memoirs  Best Seller  Biographies & Memoirs   \n",
       "2  Biographies and memoirs  Best Seller  Biographies & Memoirs   \n",
       "3  Biographies and memoirs               Humor & Entertainment   \n",
       "4  Biographies and memoirs               Humor & Entertainment   \n",
       "\n",
       "                                               title         author  ratting  \\\n",
       "0                                            Untamed  Glennon Doyle      4.7   \n",
       "1  The Splendid and the Vile: A Saga of Churchill...    Erik Larson      4.7   \n",
       "2  Hidden Valley Road: Inside the Mind of an Amer...  Robert Kolker      4.6   \n",
       "3                         Wow, No Thank You.: Essays  Samantha Irby      4.3   \n",
       "4  Nobody Will Tell You This But Me: A true (as t...      Bess Kalb      4.4   \n",
       "\n",
       "   total_ratting  kindle_price  audiobook_price  hardcover_price  ...  \\\n",
       "0          20658         14.99              0.0            16.72  ...   \n",
       "1           8773         14.99              0.0            18.24  ...   \n",
       "2           3751         14.99              0.0            15.99  ...   \n",
       "3           1168         11.49              0.0             0.00  ...   \n",
       "4            440         11.99              0.0            12.81  ...   \n",
       "\n",
       "   print_length  language        asin text_to_speach  enhanced_typesetting  \\\n",
       "0           302   English  B07VSZTKJ8        Enabled               Enabled   \n",
       "1           546   English  B07TRVW6VX        Enabled               Enabled   \n",
       "2           370   English  B07TZYFR71        Enabled               Enabled   \n",
       "3           311   English  B07W3J49XM        Enabled               Enabled   \n",
       "4           208   English  B07TRX3TXP        Enabled               Enabled   \n",
       "\n",
       "     x_ray      lending  simultaneous_device_usage screen_reader  \\\n",
       "0  Enabled  Not Enabled                                            \n",
       "1  Enabled  Not Enabled                                            \n",
       "2  Enabled  Not Enabled                                            \n",
       "3  Enabled  Not Enabled                                            \n",
       "4  Enabled  Not Enabled                                            \n",
       "\n",
       "                                           book_link  \n",
       "0  https://www.amazon.com/Untamed-Glennon-Doyle-e...  \n",
       "1  https://www.amazon.com/Splendid-Vile-Churchill...  \n",
       "2  https://www.amazon.com/Hidden-Valley-Road-Insi...  \n",
       "3  https://www.amazon.com/Wow-No-Thank-You-Essays...  \n",
       "4  https://www.amazon.com/Nobody-Will-Tell-You-Th...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_scrape_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treck the error by access the book url (without looping)\n",
    "driver.get(buku.iloc[171][0])\n",
    "sleep(3)\n",
    "link_number += 13\n",
    "xx = []\n",
    "\n",
    "#checking price selected\n",
    "item_selected = \"\"\n",
    "try:\n",
    "    price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "    selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected\")\n",
    "    item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "except:\n",
    "    try:\n",
    "        price_list_selected = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        selected_price = price_list_selected.find_element_by_class_name(\"swatchElement.selected.resizedSwatchElement\")\n",
    "        item_selected = selected_price.find_element_by_xpath(\"span/span[1]/span/a/span[1]\").text\n",
    "    except:\n",
    "        print(\"Fail to find kindle button in book-\",link_number)\n",
    "\n",
    "\n",
    "if item_selected == 'Kindle':\n",
    "    try:\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "    except:\n",
    "        print(\"Fail to crawlling the data in book-\",link_number)\n",
    "else:\n",
    "    try:\n",
    "        #go to kindle page\n",
    "        kindle_button = driver.find_element_by_class_name(\"a-unordered-list.a-nostyle.a-button-list.a-horizontal\")\n",
    "        kindle_link = kindle_button.find_element_by_xpath('li[1]/span/span[1]/span/a').get_property('href')\n",
    "        driver.get(kindle_link)\n",
    "        sleep(3)\n",
    "\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "    except:\n",
    "        book_scraper = get_scrape_blueprint(driver, link_number)\n",
    "        xx.append(book_scraper)\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCROLL DOWN (u can use this instruction in every website to scroll down its page)\n",
    "\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
